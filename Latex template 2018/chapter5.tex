\chapter{مسیریابی برای اجماع ربات‌ها}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{مقدمه}
در این قسمت به پیاده‌سازی الگوریتم‌های فصل \ref{ch path planning} برای اجماع ربات‌ها به صورت آنلاین پرداخته می‌شود. منظور از آنلاین بودن برنامه‌ریزی این است که در هر گام زمانی، ربات مجددا الگوریتم مسیریابی را اجرا نماید. برای مسیریابی با میدان پتانسیل، در ابتدا اجماع با شکل‌دهی ثابت برای عبور از موانع تلاش می‌کند اما پس از اشاره به ایرادات این روش، در ادامه کار شکل‌گیری پلتون شکسته و دوباره به شکل‌گیری تلاش خواهند کرد. همچنین موانع به صورت ثابت و متحرک خواهند بود.

\section{میدان پتانسیل}
در این قسمت تمامی مسیریابی‌ها تنها با میدان پتانسیل انجام شده است. در ابتدا شکل‌گیری ثابت و سپس شکل‌گیری با قابلیت شکسته شدن مورد بررسی قرار خواهد گرفت. قابل ذکر است که در هر دو روش تا جای ممکن محاسبات به صورت نامتمرکز\LTRfootnote{distributed} بوده است.

\subsection{جلوگیری از برخورد با موانع با شکل‌گیری ثابت}
در این قسمت یک شکل‌گیری ثابت برای دسته ربات‌ها در نظر گرفته شده است. ایده اصلی این است که نیروی جاذبه برای رهبر که در مرکز دسته پلتون حضور دارد و نیروی دافعه برای هر ربات محاسبه گردد و در نهایت نیروی کلی به دست آید. در این راستا برای محاسبه دو ایده برای پیاده‌سازی به وجود می‌آید اول اینکه همانند شکل \ref{Fig platoon-potential-field-simulink} به صورت متمرکز تمام داده‌ها به محاسبه‌گری که مسئول محاسبه مسیر ربات رهبر است فرستاده شود و نیروهای دافعه و جاذبه در آن محاسبه گردند.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.25]{Images/platoon-potential-field-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش شکل‌گیری ثابت با محاسبات متمرکز}\label{Fig platoon-potential-field-simulink}
\end{figure}


مکان ربات‌ها برای روش متمرکز به رنگ‌های سبز، آبی و قرمز و موانع با رنگ سیاه در شکل \ref{Fig platoon-potential-field-pos} به نمایش در آمده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-potential-field-pos.jpg}
	\caption{مکان ربات‌ها در روش شکل‌گیری ثابت با محاسبات متمرکز}\label{Fig platoon-potential-field-pos}
\end{figure}

در روش دوم، برای اینکه دوره محاسبات کاهش یابد، همانند شکل \ref{Fig platoon-potential-field-distributed-simulink} محاسبه نیروی دافعه ناشی از هر ربات، به صورت نامتمرکز و جداگانه در هر ربات محاسبه می‌شود و سپس به ربات رهبر فرستاده می‌شود. محاسبه‌گر ربات رهبر تنها مقادیر را با هم جمع می‌نماید تا به نیروی دافعه برسد. اما نیروی جاذبه همچنان توسط رهبر محاسبه می‌گردد.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.25]{Images/platoon-potential-field-distributed-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش شکل‌گیری ثابت با محاسبات نامتمرکز}\label{Fig platoon-potential-field-distributed-simulink}
\end{figure}


مکان ربات‌ها برای روش نامتمرکز در شکل \ref{Fig platoon-potential-field-distributed-pos} به نمایش در آمده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-potential-field-distributed-pos.jpg}
	\caption{مکان ربات‌ها در روش شکل‌گیری ثابت با محاسبات نامتمرکز}\label{Fig platoon-potential-field-distributed-pos}
\end{figure}


مشکل اصلی این روش این است که امکان دارد هر ربات از جهت مختلفی به طور همزمان به مانع نزدیک شوند، مخصوصا در شرایطی که مانع متحرک باشد، لذا نیاز داریم هر ربات به تنهایی میدان پتانسیل مخصوص به خود را داشته باشد. که در قسمت بعد این ایده پیاده‌سازی گشته است.

\subsection{جلوگیری از برخورد با موانع با شکل‌گیری شکننده}\label{sec potential-field for every robot}
در این روش هر ربات با میدان پتانسیل مخصوص به خود مسیریابی را انجام می‌دهد و نقطه‌ای که در هر لحظه باید در اجماع قرار گیرد به عنوان نقطه هدف در نظر گرفته می‌شود. بلوک‌های شبیه‌سازی در شکل \ref{Fig platoon-potential-field-independent-simulink} و نتیجه حرکت ربات‌ها در شکل \ref{Fig platoon-potential-field-independent-pos} به نمایش در آمده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-potential-field-independent-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش شکل‌گیری شکننده}\label{Fig platoon-potential-field-independent-simulink}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-potential-field-independent-pos.jpg}
	\caption{مکان ربات‌ها در روش شکل‌گیری شکننده}\label{Fig platoon-potential-field-independent-pos}
\end{figure}



\section{روش‌های ابتکاری}
در این قسمت روش‌های ابتکاری فصل \ref{ch path planning} پیاده‌سازی شده‌اند. این مسیریابی‌ها به صورت آنلاین انجام شده است تا از برخورد با موانع متحرک نیز بتوان اجتناب کرد. روش پیاده‌سازی به این صورت است که در عامل رهبر، این مسیریابی انجام و ربات طبق آن حرکت می‌نماید. سایر ربات‌ها همانند بخش \ref{sec potential-field for every robot} از میدان پتانسیل برای رسیدن به مکان مطلوب تعیین شده از طرف کنترل‌کننده پلتون و دوری از موانع به صورت انفرادی، استفاده می‌کنند.

\subsection{\lr{BFS}}
نحوه پیاده‌سازی مسیریابی \lr{BFS} توسط اجماع ربات‌ها در شکل \ref{Fig platoon-BSF-simulink} و مسیر پیموده شده در شکل \ref{Fig platoon-BSF-pos} قابل مشاهده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.22]{Images/platoon-BFS-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش \lr{BFS}}\label{Fig platoon-BSF-simulink}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-BFS-pos.jpg}
	\caption{مکان ربات‌ها در روش \lr{BFS}}\label{Fig platoon-BSF-pos}
\end{figure}

\newpage
\subsection{\lr{Greedy best-first search}}
پیاده‌سازی روش \lr{Greedy best-first search} برای مسیریابی اجماع ربات‌ها همراه با نتیجه‌ آن، به ترتیب در شکل‌های \ref{Fig platoon-Greedy-simulink} و \ref{Fig platoon-Greedy-pos} آمده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.22]{Images/platoon-Greedy-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش \lr{Greedy best-first search}}\label{Fig platoon-Greedy-simulink}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-Greedy-pos.jpg}
	\caption{مکان ربات‌ها در روش \lr{Greedy best-first search}}\label{Fig platoon-Greedy-pos}
\end{figure}


\subsection{$A^*$}
روش $A^*$ برای مسیریابی اجماع ربات‌ها در شکل \ref{Fig platoon-A-star-simulink} پیاده‌سازی شده است. مسیر پیموده شده توسط هر ربات، در شکل \ref{Fig platoon-A-star-pos} قابل مشاهده می‌باشد.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.22]{Images/platoon-A-star-simulink.png}
	\caption{بلوک‌های شبیه‌سازی در روش $A^*$}\label{Fig platoon-A-star-simulink}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-A-star-pos.jpg}
	\caption{مکان ربات‌ها در روش $A^*$}\label{Fig platoon-A-star-pos}
\end{figure}

\section{\lr{Q-learning}}
در این قسمت نتایج الگوریتم \lr{Q-learning} بررسی خواهد شد. قابل ذکر است که مقادیر یادگیری به شرح زیر هستند:
\begin{itemize}
	\item $\alpha$ = 0/9
	\item $\gamma$ = 0/9
	\item بیشترین تعداد گام‌ها = 100
	\item حد بیشترین اختلاف در تابع \lr{V} = 0/0001
	\item $R=-\|a\|_2$
\end{itemize}

بلوک‌های شبیه‌سازی همانند شکل \ref{Fig platoon-QL} بسته شده‌اند. همچنین مسیر پیموده شده توسط هر ربات در شکل \ref{Fig platoon-QL-pos} نشان داده شده است. در پیاده‌سازی آنلاین، مقادیر \lr{V} و \lr{Q} نگه‌داری می‌شوند و در هر دوره محاسباتی تنها به روزرسانی می‌گردند. لذا همانطور که مشخص است در یکی دو سیاست اولیه اخذ شده، هنوز به بهینگی نرسیده‌ایم اما پس از 2 انتخاب، سیاست‌ها بهینه هستند.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.25]{Images/platoon-QL.png}
	\caption{بلوک‌های شبیه‌سازی در روش \lr{Q-learning}}\label{Fig platoon-QL}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/platoon-QL-pos.jpg}
	\caption{مکان ربات‌ها در روش \lr{Q-learning}}\label{Fig platoon-QL-pos}
\end{figure}

\newpage
\section{مسیریابی در حضور موانع متحرک}
در ادامه نتایج گرفته شده در برابر موانع متحرک برای الگوریتم‌های بالا به نمایش در آمده‌اند. قابل ذکر است که فیلم پاسخ‌های گرفته شده در \cite{roozbeh2020} موجود می‌باشد. روش مواجهه به موانع متحرک به این صورت بوده است که جابه‌جایی آن‌ها در یک بازه زمانی محاسبه گردد و سپس طبق جابه‌جایی انجام شده در لحظه قبل و داشتن موقعیت لحظه حال، موقعیت مانع متحرک در لحظه بعدی تقریب زده شود. این روش بسیار ساده است و قابل ارتقا و دقیق‌تر شدن می‌باشد.
\begin{equation}
	X_{n+1} = X_n + (X_n - X_{n-1}) = 2X_n - X_{n-1}
\end{equation}

شبیه‌سازی برای \lr{Q-learning} در عکس \ref{Fig dynamic-QL} نشان داده شده است.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.25]{Images/dynamic-QL.png}
	\caption{بلوک‌های شبیه‌سازی در روش \lr{Q-learning} همراه با مانع متحرک}\label{Fig dynamic-QL}
\end{figure}

نتایج برای هر الگوریتم نیز در عکس‌های زیر نشان داده شده‌اند. مسیرهای سبز، قرمز و آبی توسط ربات‌های پلتون و مسیر مشکی رنگ توسط مانع متحرک که خود نیز یک ربات است پیموده شده‌اند.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/dynamic-QL.jpg}
	\caption{مکان ربات‌ها در روش \lr{Q-learning} همراه با مانع متحرک}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/dynamic-potential-field.jpg}
	\caption{مکان ربات‌ها در روش میدان پتانسیل همراه با مانع متحرک}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/dynamic-BFS.jpg}
	\caption{مکان ربات‌ها در روش \lr{BFS} همراه با مانع متحرک}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/dynamic-Greedy.jpg}
	\caption{مکان ربات‌ها در روش \lr{Greedy best-first search} همراه با مانع متحرک}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.2]{Images/dynamic-A-star.jpg}
	\caption{مکان ربات‌ها در روش $A^*$ همراه با مانع متحرک}
\end{figure}







